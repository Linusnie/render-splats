{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import torch\n",
    "import gsplat\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from render_splats.dataloading import load_splatfacto, load_3dgs, bmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for nerf_synthetic/lego\n",
    "height, width = 800, 800\n",
    "fx, fy = 1111.1110311937682, 1111.1110311937682\n",
    "camera_pose = torch.tensor([\n",
    "\t[ 0.6374,  0.7705, -0.,      0.    ],\n",
    "\t[ 0.2536, -0.2098, -0.9443, -0.    ],\n",
    "\t[-0.7276,  0.6019, -0.3291,  4.0311],\n",
    "\t[ 0.,      0.,      0.,      1.    ],\n",
    "], device='cuda')\n",
    "\n",
    "def render_splats_legacy(camera_pose, gs_data):\n",
    "    resolution_factor = 1\n",
    "    means2d, depths, radii, conics, compensation, num_tiles_hit, cov3d = gsplat.project_gaussians(\n",
    "        means3d=gs_data.means,\n",
    "        scales=gs_data.scales,\n",
    "        glob_scale=1.,\n",
    "        quats=gs_data.quaternions,\n",
    "        # viewmat=torch.tensor(view_matrix, device=\"cuda\", dtype=torch.float32),\n",
    "        viewmat=camera_pose,\n",
    "        fx=fx,\n",
    "        fy=fy,\n",
    "        cx=width / 2,\n",
    "        cy=height / 2,\n",
    "        img_height=round(height / resolution_factor),\n",
    "        img_width=round(width / resolution_factor),\n",
    "        block_width=16,\n",
    "        clip_thresh=0.01,\n",
    "    )\n",
    "\n",
    "    camera_center = torch.linalg.inv(camera_pose)[:3, -1]\n",
    "    view_dirs = bmv(gs_data.rotation.T, torch.nn.functional.normalize(gs_data.means - camera_center))\n",
    "    harmonics = gsplat.spherical_harmonics(\n",
    "        degrees_to_use=gs_data.max_sh_degree,\n",
    "        dirs=view_dirs,\n",
    "        coeffs=gs_data.features,\n",
    "    )\n",
    "    colors = harmonics + 0.5\n",
    "    rendered_image_gsplat, image_alpha = gsplat.rasterize_gaussians(\n",
    "        xys=means2d,\n",
    "        depths=depths,\n",
    "        radii=radii,\n",
    "        conics=conics,\n",
    "        num_tiles_hit=num_tiles_hit,\n",
    "        colors=colors,\n",
    "        opacity=gs_data.opacities[:, None],\n",
    "        img_height=round(height / resolution_factor),\n",
    "        img_width=round(width / resolution_factor),\n",
    "        block_width=16,\n",
    "        background=torch.ones(3, device=\"cuda\"),\n",
    "        return_alpha=True,\n",
    "    )\n",
    "    return rendered_image_gsplat\n",
    "\n",
    "def render_splats(camera_pose, gs_data):\n",
    "\trendered_image, rendered_alphas, render_info = gsplat.rasterization(\n",
    "\t\tgs_data.means,\n",
    "\t\tgs_data.quaternions,\n",
    "\t\tgs_data.scales,\n",
    "\t\tgs_data.opacities,\n",
    "\t\tgs_data.features,\n",
    "\t\tcamera_pose[None],\n",
    "\t\ttorch.tensor([\n",
    "\t\t\t[fx, 0, width / 2],\n",
    "\t\t\t[0, fy, height / 2],\n",
    "\t\t\t[0, 0, 1]\n",
    "\t\t], device='cuda')[None],\n",
    "\t\twidth, height,\n",
    "\t\tsh_degree=gs_data.max_sh_degree,\n",
    "\t\tbackgrounds=torch.ones((1, 3), device='cuda')\n",
    "\t)\n",
    "\treturn rendered_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_data = load_splatfacto('/home/linus/workspace/nerfstudio/outputs/unnamed/splatfacto/2024-05-28_124041/nerfstudio_models/step-000029999.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "New version is faster than legacy method as expected\n",
    "\n",
    "#### V1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 1.5493535995483398 ms\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "t = time.time()\n",
    "for i in range(n):\n",
    "\trendered_image = render_splats(camera_pose, gs_data)\n",
    "\ttorch.cuda.synchronize()\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'avg time: {t / n * 1e3} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 1.7884361743927002 ms\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for i in range(n):\n",
    "\trendered_image = render_splats_legacy(camera_pose, gs_data)\n",
    "\ttorch.cuda.synchronize()\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'avg time: {t / n * 1e3} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose gradients\n",
    "\n",
    "New vresion is rougly 3 times slower than legacy version.\n",
    "\n",
    "Can be mitigated by transforming gaussians to camera coordinates and rendering with identity pose.\n",
    "\n",
    "Still slightly slower, possibly due to extra rotation matrix to quaternion conversion?\n",
    "\n",
    "#### V1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 13.778949975967407 ms\n"
     ]
    }
   ],
   "source": [
    "camera_pose.requires_grad_(True)\n",
    "t = time.time()\n",
    "for i in range(n):\n",
    "\trendered_image = render_splats(camera_pose, gs_data)\n",
    "\tgrad, = torch.autograd.grad(rendered_image.mean(), camera_pose)\n",
    "\ttorch.cuda.synchronize()\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'avg time: {t / n * 1e3} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 4.621554613113403 ms\n"
     ]
    }
   ],
   "source": [
    "camera_pose.requires_grad_(True)\n",
    "t = time.time()\n",
    "for i in range(n):\n",
    "\trendered_image = render_splats_legacy(camera_pose, gs_data)\n",
    "\tgrad, = torch.autograd.grad(rendered_image.mean(), camera_pose)\n",
    "\ttorch.cuda.synchronize()\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'avg time: {t / n * 1e3} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1.0, transformed gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 5.722715854644775 ms\n"
     ]
    }
   ],
   "source": [
    "camera_pose.requires_grad_(True)\n",
    "t = time.time()\n",
    "for i in range(n):\n",
    "\trendered_image = render_splats(torch.eye(4, device='cuda'), camera_pose @ gs_data)\n",
    "\tgrad, = torch.autograd.grad(rendered_image.mean(), camera_pose)\n",
    "\ttorch.cuda.synchronize()\n",
    "t = time.time() - t\n",
    "\n",
    "print(f'avg time: {t / n * 1e3} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-splats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
